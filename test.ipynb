{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrien/Documents/flax/FlaxMixtral/.env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "model_path = \"hf-internal-testing/Mixtral-tiny\"\n",
    "token_path = \"mistralai/Mixtral-8x7B-v0.1\"\n",
    "\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, MixtralModel, MixtralConfig, FlaxMixtralModel\n",
    "config = MixtralConfig.from_pretrained(model_path)\n",
    "config.output_router_logits = True\n",
    "config.output_attentions = True\n",
    "config.output_hidden_states = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MixtralModel is using MixtralSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    }
   ],
   "source": [
    "model = MixtralModel.from_pretrained(model_path, config=config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(token_path)\n",
    "\n",
    "prompt = \"Hey, are you conscious? Can you talk to me?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "x = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.4067,  1.4824,  2.1855,  ...,  2.1699, -2.6309,  1.4844],\n",
       "          [-0.5459, -0.8843, -0.2935,  ...,  0.3994,  0.3154,  0.1948],\n",
       "          [-1.3867,  0.1390, -0.4028,  ..., -0.7080, -0.8794, -0.7305],\n",
       "          ...,\n",
       "          [ 0.5400, -1.0771,  0.5771,  ..., -0.8071, -1.1641,  0.4294],\n",
       "          [-0.0669, -0.6182,  1.4971,  ..., -1.1377,  0.9434, -0.6587],\n",
       "          [ 0.5278,  0.4001,  0.3354,  ...,  1.1787, -0.0963, -0.7915]]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[[-0.9513,  1.3742,  2.0910,  ...,  1.8151, -2.2085,  1.4657],\n",
       "          [-1.0046, -1.0591, -0.1656,  ...,  0.5409,  0.4331,  0.4100],\n",
       "          [-1.5400,  0.1457, -0.1894,  ..., -0.7366, -0.6917, -0.4431],\n",
       "          ...,\n",
       "          [ 0.4499, -1.0704,  0.5446,  ..., -0.7091, -1.0767,  0.6993],\n",
       "          [-0.1403, -0.5699,  1.3213,  ..., -1.2383,  0.9743, -0.3318],\n",
       "          [ 0.6120,  0.3999,  0.2614,  ...,  1.2715,  0.0878, -0.5480]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[-1.4910,  1.2440,  2.3478,  ...,  1.4659, -1.9996,  2.3321],\n",
       "          [-1.4066, -1.2585, -0.1159,  ...,  0.4500,  0.3790,  0.8595],\n",
       "          [-2.1107,  0.0814, -0.1963,  ..., -0.8745, -0.6745, -0.0833],\n",
       "          ...,\n",
       "          [ 0.2947, -1.0839,  0.3771,  ..., -0.5531, -1.0748,  0.6421],\n",
       "          [-0.1680, -0.6061,  1.2885,  ..., -1.1196,  1.1017, -0.3771],\n",
       "          [ 0.7433,  0.3478,  0.2059,  ...,  1.2677,  0.0713, -0.5899]]],\n",
       "        grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCCCCCCCCCCCCCCC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hf-internal-testing/Mixtral-tiny were not used when initializing FlaxMixtralModel: {('lm_head', 'kernel')}\n",
      "- This IS expected if you are initializing FlaxMixtralModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxMixtralModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some of the weights of FlaxMixtralModel were initialized in float16 precision from the model checkpoint at hf-internal-testing/Mixtral-tiny:\n",
      "[('embed_tokens', 'embedding'), ('layers', '0', 'block_sparse_moe', 'experts', '0', 'w1', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '0', 'w2', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '0', 'w3', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '1', 'w1', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '1', 'w2', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '1', 'w3', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '2', 'w1', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '2', 'w2', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '2', 'w3', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '3', 'w1', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '3', 'w2', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '3', 'w3', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '4', 'w1', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '4', 'w2', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '4', 'w3', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '5', 'w1', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '5', 'w2', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '5', 'w3', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '6', 'w1', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '6', 'w2', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '6', 'w3', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '7', 'w1', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '7', 'w2', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '7', 'w3', 'kernel'), ('layers', '0', 'block_sparse_moe', 'gate', 'kernel'), ('layers', '0', 'input_layernorm', 'weight'), ('layers', '0', 'post_attention_layernorm', 'weight'), ('layers', '0', 'self_attn', 'k_proj', 'kernel'), ('layers', '0', 'self_attn', 'o_proj', 'kernel'), ('layers', '0', 'self_attn', 'q_proj', 'kernel'), ('layers', '0', 'self_attn', 'v_proj', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '0', 'w1', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '0', 'w2', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '0', 'w3', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '1', 'w1', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '1', 'w2', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '1', 'w3', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '2', 'w1', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '2', 'w2', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '2', 'w3', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '3', 'w1', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '3', 'w2', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '3', 'w3', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '4', 'w1', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '4', 'w2', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '4', 'w3', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '5', 'w1', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '5', 'w2', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '5', 'w3', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '6', 'w1', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '6', 'w2', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '6', 'w3', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '7', 'w1', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '7', 'w2', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '7', 'w3', 'kernel'), ('layers', '1', 'block_sparse_moe', 'gate', 'kernel'), ('layers', '1', 'input_layernorm', 'weight'), ('layers', '1', 'post_attention_layernorm', 'weight'), ('layers', '1', 'self_attn', 'k_proj', 'kernel'), ('layers', '1', 'self_attn', 'o_proj', 'kernel'), ('layers', '1', 'self_attn', 'q_proj', 'kernel'), ('layers', '1', 'self_attn', 'v_proj', 'kernel'), ('norm', 'weight')]\n",
      "You should probably UPCAST the model weights to float32 if this was not intended. See [`~FlaxPreTrainedModel.to_fp32`] for further information on how to do this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCCCCCCCCCCCCCCC\n"
     ]
    }
   ],
   "source": [
    "model = FlaxMixtralModel.from_pretrained(model_path, config=config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(token_path)\n",
    "\n",
    "prompt = \"Hey, are you conscious? Can you talk to me?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"jax\")\n",
    "\n",
    "y = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[[-0.40673828,  1.4824219 ,  2.1855469 , ...,  2.1699219 ,\n",
       "          -2.6308594 ,  1.484375  ],\n",
       "         [-0.54589844, -0.88427734, -0.29345703, ...,  0.39941406,\n",
       "           0.3154297 ,  0.19482422],\n",
       "         [-1.3867188 ,  0.13903809, -0.40283203, ..., -0.7080078 ,\n",
       "          -0.87939453, -0.73046875],\n",
       "         ...,\n",
       "         [ 0.54003906, -1.0771484 ,  0.57714844, ..., -0.8071289 ,\n",
       "          -1.1640625 ,  0.42944336],\n",
       "         [-0.06689453, -0.61816406,  1.4970703 , ..., -1.1376953 ,\n",
       "           0.9433594 , -0.6586914 ],\n",
       "         [ 0.52783203,  0.40014648,  0.33544922, ...,  1.1787109 ,\n",
       "          -0.09631348, -0.7915039 ]]], dtype=float32),\n",
       " Array([[[-0.9512765 ,  1.3742137 ,  2.0909903 , ...,  1.8151293 ,\n",
       "          -2.2085001 ,  1.4656765 ],\n",
       "         [-1.0045583 , -1.0591412 , -0.16560225, ...,  0.54093945,\n",
       "           0.43313074,  0.41004956],\n",
       "         [-1.5399573 ,  0.14566039, -0.18943106, ..., -0.7365563 ,\n",
       "          -0.6916512 , -0.4430975 ],\n",
       "         ...,\n",
       "         [ 0.44989714, -1.0703536 ,  0.5446242 , ..., -0.7091343 ,\n",
       "          -1.0767226 ,  0.69930696],\n",
       "         [-0.14029716, -0.5699066 ,  1.3213382 , ..., -1.2383035 ,\n",
       "           0.9742793 , -0.3317961 ],\n",
       "         [ 0.6119936 ,  0.39994478,  0.2614372 , ...,  1.2715026 ,\n",
       "           0.08781135, -0.5480071 ]]], dtype=float32),\n",
       " Array([[[-1.4910138 ,  1.2440001 ,  2.347837  , ...,  1.4658867 ,\n",
       "          -1.9995558 ,  2.3321059 ],\n",
       "         [-1.4065796 , -1.2585348 , -0.11586622, ...,  0.4500268 ,\n",
       "           0.37901428,  0.8594837 ],\n",
       "         [-2.1106687 ,  0.08143321, -0.19634205, ..., -0.87450725,\n",
       "          -0.67447233, -0.08327945],\n",
       "         ...,\n",
       "         [ 0.2947395 , -1.0838611 ,  0.377108  , ..., -0.55314595,\n",
       "          -1.074801  ,  0.6420861 ],\n",
       "         [-0.16801266, -0.60607636,  1.2884645 , ..., -1.1196154 ,\n",
       "           1.1017209 , -0.37705478],\n",
       "         [ 0.7433374 ,  0.3478445 ,  0.20590468, ...,  1.2677363 ,\n",
       "           0.07131021, -0.5898897 ]]], dtype=float32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = []\n",
    "for i in range(len(x.attentions)):\n",
    "        for j in range(len(x.attentions[i])):\n",
    "                for k in range(len(x.attentions[i][j])):\n",
    "                        for l in range(len(x.attentions[i][j][k])):\n",
    "                                to_keep.append(np.amax(np.abs(np.array(x.attentions[i][j][k][l].detach().cpu()) - np.array(y.attentions[i][j][k][l]))))\n",
    "\n",
    "# for i in range(len(x.last_hidden_state)):\n",
    "#         for j in range(len(x.last_hidden_state[i])):\n",
    "#                                 to_keep.append(np.amax(np.abs(np.array(x.attentions[i][j].detach().cpu()) - np.array(y.attentions[i][j]))))\n",
    "\n",
    "to_keep.append(np.amax(np.abs(np.array(x.attentions[0].detach().cpu()) - np.array(y.attentions[0]))))\n",
    "\n",
    "\n",
    "for i in range(len(x.hidden_states)):\n",
    "        for j in range(len(x.hidden_states[i])):\n",
    "                for k in range(len(x.hidden_states[i][j])):\n",
    "                                to_keep.append(np.amax(np.abs(np.array(x.hidden_states[i][j][k].detach().cpu()) - np.array(y.hidden_states[i][j][k]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = []\n",
    "for i in range(len(x.attentions)):\n",
    "        for j in range(len(x.attentions[i])):\n",
    "                for k in range(len(x.attentions[i][j])):\n",
    "                        for l in range(len(x.attentions[i][j][k])):\n",
    "                                to_keep.append(np.amax(np.abs(np.array(x.attentions[i][j][k][l].detach().cpu()) - np.around(np.array(y.attentions[i][j][k][l]), 4))))\n",
    "\n",
    "# for i in range(len(x.last_hidden_state)):\n",
    "#         for j in range(len(x.last_hidden_state[i])):\n",
    "#                                 to_keep.append(np.amax(np.abs(np.array(x.attentions[i][j].detach().cpu()) - np.array(y.attentions[i][j]))))\n",
    "\n",
    "to_keep.append(np.amax(np.abs(np.array(x.attentions[0].detach().cpu()) - np.around(np.array(y.attentions[0]), 4))))\n",
    "\n",
    "\n",
    "for i in range(len(x.hidden_states)):\n",
    "        for j in range(len(x.hidden_states[i])):\n",
    "                for k in range(len(x.hidden_states[i][j])):\n",
    "                                to_keep.append(np.amax(np.abs(np.array(x.hidden_states[i][j][k].detach().cpu()) - np.around(np.array(y.hidden_states[i][j][k]), 4))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
