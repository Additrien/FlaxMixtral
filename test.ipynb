{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "x = jnp.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_device = x.device()\n",
    "array_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([1, 2, 30])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "t = torch.from_numpy(a)\n",
    "top_k=2\n",
    "torch.topk(t, top_k, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.lax.top_k(a, top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.from_numpy(a)\n",
    "print(t)\n",
    "t.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(t.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.expand_dims(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.expand(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array = np.random.uniform(1, 10, (1, 100))\n",
    "random_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(random_array, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(random_array).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(random_array).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_layers=12\n",
    "batch_size=1\n",
    "sequence_length=100\n",
    "num_experts=2\n",
    "\n",
    "expanded_shape = (num_hidden_layers, batch_size, sequence_length, 2, num_experts)\n",
    "broadcasted_random_array = random_array[None, :, :, None, None]\n",
    "\n",
    "# broadcasted_random_array = jnp.tile(broadcasted_random_array, expanded_shape)\n",
    "broadcasted_random_array = jnp.broadcast_to(broadcasted_random_array, expanded_shape)\n",
    "\n",
    "# # Proceeding with the similar operations as before\n",
    "expert_attention_mask = jnp.reshape(broadcasted_random_array, (-1, 2, num_experts))\n",
    "expert_attention_mask, expert_attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_attention_mask = (\n",
    "            torch.from_numpy(random_array[None, :, :, None, None])\n",
    "            .expand(expanded_shape)\n",
    "            .reshape(-1, 2, num_experts)\n",
    "        )\n",
    "expert_attention_mask, expert_attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming x is a PyTorch tensor\n",
    "x = torch.arange(16)  # Creates a tensor from 0 to 15\n",
    "\n",
    "# Using view to change the shape of the tensor\n",
    "y = x.view(4, 4)  # Reshapes x to a 4x4 tensor\n",
    "\n",
    "print(\"PyTorch version:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "# Assuming x is a JAX array\n",
    "x = jnp.arange(16)  # Creates an array from 0 to 15\n",
    "\n",
    "# Using reshape to change the shape of the array\n",
    "x = x.reshape((4, 4))  # Reshapes x to a 4x4 array\n",
    "\n",
    "print(\"Flax/JAX version:\", x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "sequence_length = 10\n",
    "hidden_dim = 2\n",
    "torch.zeros(\n",
    "            (batch_size * sequence_length, hidden_dim)\n",
    "        ).permute(2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.zeros((batch_size * sequence_length, hidden_dim)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming x is a PyTorch tensor with shape [2, 3, 4]\n",
    "x = torch.ones(2, 3, 4)\n",
    "print(x.shape)\n",
    "# Permute the dimensions of x\n",
    "y = x.permute(2, 0, 1)  # Rearranges dimensions to [4, 2, 3]\n",
    "\n",
    "print(\"PyTorch version, shape:\", y.shape)\n",
    "y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "# Assuming x is a JAX array with shape [2, 3, 4]\n",
    "x = jnp.ones((2, 3, 4))\n",
    "print(x.shape)\n",
    "# Transpose the dimensions of x\n",
    "x = x.transpose((2, 0, 1))  # Rearranges dimensions to [4, 2, 3]\n",
    "\n",
    "print(\"Flax/JAX version, shape:\", x.shape)\n",
    "x.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.reshape(4,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, MixtralForCausalLM\n",
    "\n",
    "model = MixtralForCausalLM.from_pretrained(\"hf-internal-testing/Mixtral-tiny\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mixtral-8x7B-v0.1\")\n",
    "\n",
    "prompt = \"Hey, are you conscious? Can you talk to me?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "x = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hey, are you conscious? Can you talk to me?_+Azureћи Excell>'; atm head intensity AnalDe rushing accidentally pand︎ ejessenimiter\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, MixtralForCausalLM\n",
    "\n",
    "model = MixtralForCausalLM.from_pretrained(\"hf-internal-testing/Mixtral-tiny\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mixtral-8x7B-v0.1\")\n",
    "\n",
    "prompt = \"Hey, are you conscious? Can you talk to me?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=30)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrien/Documents/flax/FlaxMixtral/.env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTTTTTTTTTTTTTTTT\n",
      "TTTTTTTTTTTTTTTTT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hf-internal-testing/Mixtral-tiny were not used when initializing FlaxMixtralModel: {('lm_head', 'kernel')}\n",
      "- This IS expected if you are initializing FlaxMixtralModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxMixtralModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some of the weights of FlaxMixtralModel were initialized in float16 precision from the model checkpoint at hf-internal-testing/Mixtral-tiny:\n",
      "[('embed_tokens', 'embedding'), ('layers', '0', 'block_sparse_moe', 'experts', '0', 'w1', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '0', 'w2', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '0', 'w3', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '1', 'w1', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '1', 'w2', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '1', 'w3', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '2', 'w1', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '2', 'w2', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '2', 'w3', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '3', 'w1', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '3', 'w2', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '3', 'w3', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '4', 'w1', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '4', 'w2', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '4', 'w3', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '5', 'w1', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '5', 'w2', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '5', 'w3', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '6', 'w1', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '6', 'w2', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '6', 'w3', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '7', 'w1', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '7', 'w2', 'kernel'), ('layers', '0', 'block_sparse_moe', 'experts', '7', 'w3', 'kernel'), ('layers', '0', 'block_sparse_moe', 'gate', 'kernel'), ('layers', '0', 'input_layernorm', 'weight'), ('layers', '0', 'post_attention_layernorm', 'weight'), ('layers', '0', 'self_attn', 'k_proj', 'kernel'), ('layers', '0', 'self_attn', 'o_proj', 'kernel'), ('layers', '0', 'self_attn', 'q_proj', 'kernel'), ('layers', '0', 'self_attn', 'v_proj', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '0', 'w1', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '0', 'w2', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '0', 'w3', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '1', 'w1', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '1', 'w2', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '1', 'w3', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '2', 'w1', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '2', 'w2', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '2', 'w3', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '3', 'w1', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '3', 'w2', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '3', 'w3', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '4', 'w1', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '4', 'w2', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '4', 'w3', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '5', 'w1', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '5', 'w2', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '5', 'w3', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '6', 'w1', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '6', 'w2', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '6', 'w3', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '7', 'w1', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '7', 'w2', 'kernel'), ('layers', '1', 'block_sparse_moe', 'experts', '7', 'w3', 'kernel'), ('layers', '1', 'block_sparse_moe', 'gate', 'kernel'), ('layers', '1', 'input_layernorm', 'weight'), ('layers', '1', 'post_attention_layernorm', 'weight'), ('layers', '1', 'self_attn', 'k_proj', 'kernel'), ('layers', '1', 'self_attn', 'o_proj', 'kernel'), ('layers', '1', 'self_attn', 'q_proj', 'kernel'), ('layers', '1', 'self_attn', 'v_proj', 'kernel'), ('norm', 'weight')]\n",
      "You should probably UPCAST the model weights to float32 if this was not intended. See [`~FlaxPreTrainedModel.to_fp32`] for further information on how to do this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTTTTTTTTTTTTTTTT\n",
      "TTTTTTTTTTTTTTTTT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FlaxBaseModelOutput(last_hidden_state=Array([[[-1.4910138 ,  1.2440001 ,  2.347837  , ...,  1.4658867 ,\n",
       "         -1.9995558 ,  2.3321059 ],\n",
       "        [-1.4065796 , -1.2585348 , -0.11586622, ...,  0.4500268 ,\n",
       "          0.37901428,  0.8594837 ],\n",
       "        [-2.1106687 ,  0.08143321, -0.19634205, ..., -0.87450725,\n",
       "         -0.67447233, -0.08327945],\n",
       "        ...,\n",
       "        [ 0.2947395 , -1.0838611 ,  0.377108  , ..., -0.55314595,\n",
       "         -1.074801  ,  0.6420861 ],\n",
       "        [-0.16801266, -0.60607636,  1.2884645 , ..., -1.1196154 ,\n",
       "          1.1017209 , -0.37705478],\n",
       "        [ 0.7433374 ,  0.3478445 ,  0.20590468, ...,  1.2677363 ,\n",
       "          0.07131021, -0.5898897 ]]], dtype=float32), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, FlaxMixtralModel\n",
    "\n",
    "model = FlaxMixtralModel.from_pretrained(\"hf-internal-testing/Mixtral-tiny\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mixtral-8x7B-v0.1\")\n",
    "\n",
    "prompt = \"Hey, are you conscious? Can you talk to me?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"jax\")\n",
    "\n",
    "x = model(**inputs)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, FlaxMixtralForCausalLM\n",
    "\n",
    "model = FlaxMixtralForCausalLM.from_pretrained(\"hf-internal-testing/Mixtral-tiny\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mixtral-8x7B-v0.1\")\n",
    "\n",
    "prompt = \"Hey, are you conscious? Can you talk to me?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"jax\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=30)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, FlaxLlamaModel\n",
    "\n",
    "model = FlaxLlamaModel.from_pretrained(\"hf-internal-testing/tiny-random-LlamaForCausalLM\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mixtral-8x7B-v0.1\")\n",
    "\n",
    "prompt = \"Hey, are you conscious? Can you talk to me?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"jax\")\n",
    "\n",
    "x = model(**inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
